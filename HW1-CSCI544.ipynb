{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/hemanthbodala/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install bs4 # in case you don't have it installed\n",
    "\n",
    "# Dataset: https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanthbodala/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3418: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "b'Skipping line 16148: expected 15 fields, saw 22\\nSkipping line 20100: expected 15 fields, saw 22\\nSkipping line 45178: expected 15 fields, saw 22\\nSkipping line 48700: expected 15 fields, saw 22\\nSkipping line 63331: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 86053: expected 15 fields, saw 22\\nSkipping line 88858: expected 15 fields, saw 22\\nSkipping line 115017: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 137366: expected 15 fields, saw 22\\nSkipping line 139110: expected 15 fields, saw 22\\nSkipping line 165540: expected 15 fields, saw 22\\nSkipping line 171813: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 203723: expected 15 fields, saw 22\\nSkipping line 209366: expected 15 fields, saw 22\\nSkipping line 211310: expected 15 fields, saw 22\\nSkipping line 246351: expected 15 fields, saw 22\\nSkipping line 252364: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 267003: expected 15 fields, saw 22\\nSkipping line 268957: expected 15 fields, saw 22\\nSkipping line 303336: expected 15 fields, saw 22\\nSkipping line 306021: expected 15 fields, saw 22\\nSkipping line 311569: expected 15 fields, saw 22\\nSkipping line 316767: expected 15 fields, saw 22\\nSkipping line 324009: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 359107: expected 15 fields, saw 22\\nSkipping line 368367: expected 15 fields, saw 22\\nSkipping line 381180: expected 15 fields, saw 22\\nSkipping line 390453: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 412243: expected 15 fields, saw 22\\nSkipping line 419342: expected 15 fields, saw 22\\nSkipping line 457388: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 459935: expected 15 fields, saw 22\\nSkipping line 460167: expected 15 fields, saw 22\\nSkipping line 466460: expected 15 fields, saw 22\\nSkipping line 500314: expected 15 fields, saw 22\\nSkipping line 500339: expected 15 fields, saw 22\\nSkipping line 505396: expected 15 fields, saw 22\\nSkipping line 507760: expected 15 fields, saw 22\\nSkipping line 513626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 527638: expected 15 fields, saw 22\\nSkipping line 534209: expected 15 fields, saw 22\\nSkipping line 535687: expected 15 fields, saw 22\\nSkipping line 547671: expected 15 fields, saw 22\\nSkipping line 549054: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 599929: expected 15 fields, saw 22\\nSkipping line 604776: expected 15 fields, saw 22\\nSkipping line 609937: expected 15 fields, saw 22\\nSkipping line 632059: expected 15 fields, saw 22\\nSkipping line 638546: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 665017: expected 15 fields, saw 22\\nSkipping line 677680: expected 15 fields, saw 22\\nSkipping line 684370: expected 15 fields, saw 22\\nSkipping line 720217: expected 15 fields, saw 29\\n'\n",
      "b'Skipping line 723240: expected 15 fields, saw 22\\nSkipping line 723433: expected 15 fields, saw 22\\nSkipping line 763891: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 800288: expected 15 fields, saw 22\\nSkipping line 802942: expected 15 fields, saw 22\\nSkipping line 803379: expected 15 fields, saw 22\\nSkipping line 805122: expected 15 fields, saw 22\\nSkipping line 821899: expected 15 fields, saw 22\\nSkipping line 831707: expected 15 fields, saw 22\\nSkipping line 842829: expected 15 fields, saw 22\\nSkipping line 843604: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 863904: expected 15 fields, saw 22\\nSkipping line 875655: expected 15 fields, saw 22\\nSkipping line 886796: expected 15 fields, saw 22\\nSkipping line 892299: expected 15 fields, saw 22\\nSkipping line 902518: expected 15 fields, saw 22\\nSkipping line 903079: expected 15 fields, saw 22\\nSkipping line 912678: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 932953: expected 15 fields, saw 22\\nSkipping line 936838: expected 15 fields, saw 22\\nSkipping line 937177: expected 15 fields, saw 22\\nSkipping line 947695: expected 15 fields, saw 22\\nSkipping line 960713: expected 15 fields, saw 22\\nSkipping line 965225: expected 15 fields, saw 22\\nSkipping line 980776: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 999318: expected 15 fields, saw 22\\nSkipping line 1007247: expected 15 fields, saw 22\\nSkipping line 1015987: expected 15 fields, saw 22\\nSkipping line 1018984: expected 15 fields, saw 22\\nSkipping line 1028671: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1063360: expected 15 fields, saw 22\\nSkipping line 1066195: expected 15 fields, saw 22\\nSkipping line 1066578: expected 15 fields, saw 22\\nSkipping line 1066869: expected 15 fields, saw 22\\nSkipping line 1068809: expected 15 fields, saw 22\\nSkipping line 1069505: expected 15 fields, saw 22\\nSkipping line 1087983: expected 15 fields, saw 22\\nSkipping line 1108184: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1118137: expected 15 fields, saw 22\\nSkipping line 1142723: expected 15 fields, saw 22\\nSkipping line 1152492: expected 15 fields, saw 22\\nSkipping line 1156947: expected 15 fields, saw 22\\nSkipping line 1172563: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1209254: expected 15 fields, saw 22\\nSkipping line 1212966: expected 15 fields, saw 22\\nSkipping line 1236533: expected 15 fields, saw 22\\nSkipping line 1237598: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1273825: expected 15 fields, saw 22\\nSkipping line 1277898: expected 15 fields, saw 22\\nSkipping line 1283654: expected 15 fields, saw 22\\nSkipping line 1286023: expected 15 fields, saw 22\\nSkipping line 1302038: expected 15 fields, saw 22\\nSkipping line 1305179: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1326022: expected 15 fields, saw 22\\nSkipping line 1338120: expected 15 fields, saw 22\\nSkipping line 1338503: expected 15 fields, saw 22\\nSkipping line 1338849: expected 15 fields, saw 22\\nSkipping line 1341513: expected 15 fields, saw 22\\nSkipping line 1346493: expected 15 fields, saw 22\\nSkipping line 1373127: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1389508: expected 15 fields, saw 22\\nSkipping line 1413951: expected 15 fields, saw 22\\nSkipping line 1433626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1442698: expected 15 fields, saw 22\\nSkipping line 1472982: expected 15 fields, saw 22\\nSkipping line 1482282: expected 15 fields, saw 22\\nSkipping line 1487808: expected 15 fields, saw 22\\nSkipping line 1500636: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1511479: expected 15 fields, saw 22\\nSkipping line 1532302: expected 15 fields, saw 22\\nSkipping line 1537952: expected 15 fields, saw 22\\nSkipping line 1539951: expected 15 fields, saw 22\\nSkipping line 1541020: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1594217: expected 15 fields, saw 22\\nSkipping line 1612264: expected 15 fields, saw 22\\nSkipping line 1615907: expected 15 fields, saw 22\\nSkipping line 1621859: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1653542: expected 15 fields, saw 22\\nSkipping line 1671537: expected 15 fields, saw 22\\nSkipping line 1672879: expected 15 fields, saw 22\\nSkipping line 1674523: expected 15 fields, saw 22\\nSkipping line 1677355: expected 15 fields, saw 22\\nSkipping line 1703907: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1713046: expected 15 fields, saw 22\\nSkipping line 1722982: expected 15 fields, saw 22\\nSkipping line 1727290: expected 15 fields, saw 22\\nSkipping line 1744482: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1803858: expected 15 fields, saw 22\\nSkipping line 1810069: expected 15 fields, saw 22\\nSkipping line 1829751: expected 15 fields, saw 22\\nSkipping line 1831699: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1863131: expected 15 fields, saw 22\\nSkipping line 1867917: expected 15 fields, saw 22\\nSkipping line 1874790: expected 15 fields, saw 22\\nSkipping line 1879952: expected 15 fields, saw 22\\nSkipping line 1880501: expected 15 fields, saw 22\\nSkipping line 1886655: expected 15 fields, saw 22\\nSkipping line 1887888: expected 15 fields, saw 22\\nSkipping line 1894286: expected 15 fields, saw 22\\nSkipping line 1895400: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1904040: expected 15 fields, saw 22\\nSkipping line 1907604: expected 15 fields, saw 22\\nSkipping line 1915739: expected 15 fields, saw 22\\nSkipping line 1921514: expected 15 fields, saw 22\\nSkipping line 1939428: expected 15 fields, saw 22\\nSkipping line 1944342: expected 15 fields, saw 22\\nSkipping line 1949699: expected 15 fields, saw 22\\nSkipping line 1961872: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 1968846: expected 15 fields, saw 22\\nSkipping line 1999941: expected 15 fields, saw 22\\nSkipping line 2001492: expected 15 fields, saw 22\\nSkipping line 2011204: expected 15 fields, saw 22\\nSkipping line 2025295: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2041266: expected 15 fields, saw 22\\nSkipping line 2073314: expected 15 fields, saw 22\\nSkipping line 2080133: expected 15 fields, saw 22\\nSkipping line 2088521: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2103490: expected 15 fields, saw 22\\nSkipping line 2115278: expected 15 fields, saw 22\\nSkipping line 2153174: expected 15 fields, saw 22\\nSkipping line 2161731: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2165250: expected 15 fields, saw 22\\nSkipping line 2175132: expected 15 fields, saw 22\\nSkipping line 2206817: expected 15 fields, saw 22\\nSkipping line 2215848: expected 15 fields, saw 22\\nSkipping line 2223811: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2257265: expected 15 fields, saw 22\\nSkipping line 2259163: expected 15 fields, saw 22\\nSkipping line 2263291: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2301943: expected 15 fields, saw 22\\nSkipping line 2304371: expected 15 fields, saw 22\\nSkipping line 2306015: expected 15 fields, saw 22\\nSkipping line 2312186: expected 15 fields, saw 22\\nSkipping line 2314740: expected 15 fields, saw 22\\nSkipping line 2317754: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2383514: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2449763: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2589323: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2775036: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2935174: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3078830: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3123091: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 3185533: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4150395: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 4748401: expected 15 fields, saw 22\\n'\n"
     ]
    }
   ],
   "source": [
    "url = 'https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Kitchen_v1_00.tsv.gz'\n",
    "data = pd.read_table(url,sep = '\\t', error_bad_lines=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426900 , 241948 , 349547 , 731733 , 3124759\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>37000337</td>\n",
       "      <td>R3DT59XH7HXR9K</td>\n",
       "      <td>B00303FI0G</td>\n",
       "      <td>529320574</td>\n",
       "      <td>Arthur Court Paper Towel Holder</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Beautiful. Looks great on counter</td>\n",
       "      <td>Beautiful.  Looks great on counter.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>15272914</td>\n",
       "      <td>R1LFS11BNASSU8</td>\n",
       "      <td>B00JCZKZN6</td>\n",
       "      <td>274237558</td>\n",
       "      <td>Olde Thompson Bavaria Glass Salt and Pepper Mi...</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Awesome &amp; Self-ness</td>\n",
       "      <td>I personally have 5 days sets and have also bo...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>36137863</td>\n",
       "      <td>R296RT05AG0AF6</td>\n",
       "      <td>B00JLIKA5C</td>\n",
       "      <td>544675303</td>\n",
       "      <td>Progressive International PL8 Professional Man...</td>\n",
       "      <td>Kitchen</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Fabulous and worth every penny</td>\n",
       "      <td>Fabulous and worth every penny. Used for clean...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     37000337  R3DT59XH7HXR9K  B00303FI0G       529320574   \n",
       "1          US     15272914  R1LFS11BNASSU8  B00JCZKZN6       274237558   \n",
       "2          US     36137863  R296RT05AG0AF6  B00JLIKA5C       544675303   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0                    Arthur Court Paper Towel Holder          Kitchen   \n",
       "1  Olde Thompson Bavaria Glass Salt and Pepper Mi...          Kitchen   \n",
       "2  Progressive International PL8 Professional Man...          Kitchen   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0          5.0            0.0          0.0    N                 Y   \n",
       "1          5.0            0.0          1.0    N                 Y   \n",
       "2          5.0            0.0          0.0    N                 Y   \n",
       "\n",
       "                     review_headline  \\\n",
       "0  Beautiful. Looks great on counter   \n",
       "1                Awesome & Self-ness   \n",
       "2     Fabulous and worth every penny   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                Beautiful.  Looks great on counter.  2015-08-31  \n",
       "1  I personally have 5 days sets and have also bo...  2015-08-31  \n",
       "2  Fabulous and worth every penny. Used for clean...  2015-08-31  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print((data['star_rating']==1).sum(),\",\",(data['star_rating']==2).sum(),\",\",(data['star_rating']==3).sum(),\",\",(data['star_rating']==4).sum(),\",\",(data['star_rating']==5).sum())\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data.drop(['marketplace', 'customer_id', 'product_id', 'product_category', 'helpful_votes', 'total_votes', 'vine', 'verified_purchase', 'review_headline', 'review_date', 'review_id', 'product_parent', 'product_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.dropna()\n",
    "data1 = data1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "nval1 = data1.isna().sum()\n",
    "print(len(nval1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Beautiful.  Looks great on counter.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I personally have 5 days sets and have also bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Fabulous and worth every penny. Used for clean...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body\n",
       "0          5.0                Beautiful.  Looks great on counter.\n",
       "1          5.0  I personally have 5 days sets and have also bo...\n",
       "2          5.0  Fabulous and worth every penny. Used for clean..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data1.index)\n",
    "data1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelling Reviews:\n",
    "## The reviews with rating 4,5 are labelled to be 1 and 1,2 are labelled as 0. Discard the reviews with rating 3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349539 , 668809 , 3856296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanthbodala/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1684: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = infer_fill_value(value)\n",
      "/Users/hemanthbodala/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Beautiful.  Looks great on counter.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I personally have 5 days sets and have also bo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Fabulous and worth every penny. Used for clean...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   star_rating                                        review_body  label\n",
       "0          5.0                Beautiful.  Looks great on counter.    1.0\n",
       "1          5.0  I personally have 5 days sets and have also bo...    1.0\n",
       "2          5.0  Fabulous and worth every penny. Used for clean...    1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = data1[data1.star_rating != 3]\n",
    "data2.loc[data2.star_rating < 3, \"label\"] = 0\n",
    "data2.loc[data2.star_rating > 3, \"label\"] = 1\n",
    "print((data1['star_rating']==3).sum(),\",\",(data2['label']==0).sum(),\",\",(data2['label']==1).sum())\n",
    "\n",
    "data2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## We select 200000 reviews randomly with 100,000 positive and 100,000 negative reviews.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>its too small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>The burr grinder creates uniform ground coffee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>My muffins were sticking to my non-stick muffi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                      its too small    0.0\n",
       "2431470          2.0  The burr grinder creates uniform ground coffee...    0.0\n",
       "2063439          2.0  My muffins were sticking to my non-stick muffi...    0.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_p = data2\n",
    "data_p = data2[data2.label != 1]\n",
    "data_n = data2\n",
    "\n",
    "data_n = data2[data2.label != 0]\n",
    "data_p.head()\n",
    "len(data_n.index)\n",
    "data_pf = data_p.sample(n = 100000, random_state=1)\n",
    "len(data_pf.index)\n",
    "data_pf.head()\n",
    "data_nf = data_n.sample(n = 100000, random_state=1)\n",
    "len(data_nf.index)\n",
    "data_nf.head()\n",
    "frames = [data_pf, data_nf]\n",
    "data_final = pd.concat(frames)\n",
    "result_len3 = data_final['review_body'].map(str).apply(len).mean()\n",
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Convert the all reviews into the lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>its too small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>the burr grinder creates uniform ground coffee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>my muffins were sticking to my non-stick muffi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                      its too small    0.0\n",
       "2431470          2.0  the burr grinder creates uniform ground coffee...    0.0\n",
       "2063439          2.0  my muffins were sticking to my non-stick muffi...    0.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final['review_body'] = data_final['review_body'].str.lower()\n",
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hemanthbodala/opt/anaconda3/lib/python3.8/site-packages/bs4/__init__.py:332: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "data_final['review_body']=data_final['review_body'].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))\n",
    "#data_final['review_body'] = data_final.review_body.apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "data_final['review_body']=data_final['review_body'].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "#data_final['review_body'] = data_final.review_body.apply(lambda x: bs4.BeautifulSoup(x, 'lxml').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>its too small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>the burr grinder creates uniform ground coffee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>my muffins were sticking to my non-stick muffi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                      its too small    0.0\n",
       "2431470          2.0  the burr grinder creates uniform ground coffee...    0.0\n",
       "2063439          2.0  my muffins were sticking to my non-stick muffi...    0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove non-alphabetical characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()\n",
    "import contractions\n",
    "def contractionfunction(s):\n",
    "    s = contractions.fix(s)\n",
    "\n",
    "    return s\n",
    "data_final['review_body']=data_final['review_body'].apply(lambda x:contractionfunction(x))\n",
    "#data_final.review_body.str.replace('[^a-z]+', ' ')\n",
    "data_final['review_body']=data_final['review_body'].apply(lambda x: \" \".join([re.sub('[^a-z]+','', x) for x in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>its too small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>the burr grinder creates uniform ground coffee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>my muffins were sticking to my nonstick muffin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                      its too small    0.0\n",
       "2431470          2.0  the burr grinder creates uniform ground coffee...    0.0\n",
       "2063439          2.0  my muffins were sticking to my nonstick muffin...    0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the extra spaces between the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>its too small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>the burr grinder creates uniform ground coffee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>my muffins were sticking to my nonstick muffin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                      its too small    0.0\n",
       "2431470          2.0  the burr grinder creates uniform ground coffee...    0.0\n",
       "2063439          2.0  my muffins were sticking to my nonstick muffin...    0.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_r1.str.replace('  ', '')\n",
    "data_final['review_body'] = data_final.review_body.replace('\\s+', ' ', regex=True)\n",
    "#data_r3.str.count(\"                                                            \").sum()\n",
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform contractions on the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323.274835 , 309.18604\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>its too small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>the burr grinder creates uniform ground coffee...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>my muffins were sticking to my nonstick muffin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                      its too small    0.0\n",
       "2431470          2.0  the burr grinder creates uniform ground coffee...    0.0\n",
       "2063439          2.0  my muffins were sticking to my nonstick muffin...    0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import contractions\n",
    "#def contractionfunction(s):\n",
    "#    s = contractions.fix(s)\n",
    "\n",
    "#    return s\n",
    "#data_final['review_body']=data_final['review_body'].apply(lambda x:contractionfunction(x))\n",
    "result_len4 = data_final['review_body'].map(str).apply(len).mean()\n",
    "print(result_len3,\",\",result_len4)\n",
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove the stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>burr grinder creates uniform ground coffeeit e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>muffins sticking nonstick muffin pan tried usi...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                              small    0.0\n",
       "2431470          2.0  burr grinder creates uniform ground coffeeit e...    0.0\n",
       "2063439          2.0  muffins sticking nonstick muffin pan tried usi...    0.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "data_final['review_body']=data_final['review_body'].apply(lambda x: \" \".join([x for x in x.split() if x not in stop]))\n",
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>burr grinder creates uniform ground coffeeit e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>muffin sticking nonstick muffin pan tried usin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                              small    0.0\n",
       "2431470          2.0  burr grinder creates uniform ground coffeeit e...    0.0\n",
       "2063439          2.0  muffin sticking nonstick muffin pan tried usin...    0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data_final['review_body']=data_final['review_body'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))\n",
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.18604 , 189.56203\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2060619</th>\n",
       "      <td>1.0</td>\n",
       "      <td>small</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2431470</th>\n",
       "      <td>2.0</td>\n",
       "      <td>burr grinder creates uniform ground coffeeit e...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063439</th>\n",
       "      <td>2.0</td>\n",
       "      <td>muffin sticking nonstick muffin pan tried usin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  label\n",
       "2060619          1.0                                              small    0.0\n",
       "2431470          2.0  burr grinder creates uniform ground coffeeit e...    0.0\n",
       "2063439          2.0  muffin sticking nonstick muffin pan tried usin...    0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_len2 = data_final['review_body'].apply(len).mean()\n",
    "print(result_len4,\",\",result_len2)\n",
    "data_final.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (160000,) (160000,) Test:  ((40000,), (40000,))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train, Y_test = train_test_split(data_final['review_body'],data_final['label'], test_size=0.20, random_state=30)\n",
    "print(\"Train:\",X_train.shape,Y_train.shape,\"Test: \",(X_test.shape,Y_test.shape))\n",
    "\n",
    "vectorizer= TfidfVectorizer()\n",
    "tf_x_train = vectorizer.fit_transform(X_train)\n",
    "tf_x_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "ppm = Perceptron(max_iter=50, eta0=0.1,random_state=0)\n",
    "ppm.fit(tf_x_train,Y_train)\n",
    "y_test_pred = ppm.predict(tf_x_test)\n",
    "y_train_pred = ppm.predict(tf_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888925 , 0.8979179197112985 , 0.8775027826065207 , 0.8875929767747812\n",
      "0.868575 , 0.881884881678206 , 0.851739108737961 , 0.866549894651334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report_train=classification_report(Y_train, y_train_pred,output_dict=True)\n",
    "#print(\"Perceptron Model:\")\n",
    "#print(\"Report for Traning data Classification\")\n",
    "#print(\"Accuracy:\",report_train['accuracy'])\n",
    "#print(\"Precision:\",precision_score(Y_train, y_train_pred))\n",
    "#print(\"Recall:\",recall_score(Y_train, y_train_pred))\n",
    "#print(\"f1_score:\",f1_score(Y_train, y_train_pred))\n",
    "#print(report_train)\n",
    "print(report_train['accuracy'],\",\",precision_score(Y_train, y_train_pred),\",\",recall_score(Y_train, y_train_pred),\",\",f1_score(Y_train, y_train_pred))\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "report_test=classification_report(Y_test, y_test_pred,output_dict=True)\n",
    "#print(\"Report for Testing data Classification\")\n",
    "#print(\"Accuracy:\",report_test['accuracy'])\n",
    "#print(\"Precision:\",precision_score(Y_test, y_test_pred))\n",
    "#print(\"Recall:\",recall_score(Y_test, y_test_pred))\n",
    "#print(\"f1_score:\",f1_score(Y_test, y_test_pred))\n",
    "#print(report_test)\n",
    "print(report_test['accuracy'],\",\",precision_score(Y_test, y_test_pred),\",\",recall_score(Y_test, y_test_pred),\",\",f1_score(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93696875 , 0.9381270064205457 , 0.9355810957841948 , 0.9368523214677061\n",
      "0.89365 , 0.8967475996581712 , 0.8902140825390489 , 0.8934688971251127\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0)\n",
    "clf.fit(tf_x_train,Y_train)\n",
    "y_test_pred=clf.predict(tf_x_test)\n",
    "y_train_pred=clf.predict(tf_x_train)\n",
    "from sklearn.metrics import classification_report\n",
    "report_train=classification_report(Y_train, y_train_pred,output_dict=True)\n",
    "\n",
    "print(report_train['accuracy'],\",\",precision_score(Y_train, y_train_pred),\",\",recall_score(Y_train, y_train_pred),\",\",f1_score(Y_train, y_train_pred))\n",
    "report=classification_report(Y_test, y_test_pred,output_dict=True)\n",
    "\n",
    "print(report['accuracy'],\",\",precision_score(Y_test, y_test_pred),\",\",recall_score(Y_test, y_test_pred),\",\",f1_score(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91255625 , 0.9159835548717431 , 0.9083428171233476 , 0.9121471853317006\n",
      "0.895075 , 0.8995661824051655 , 0.889914666400519 , 0.894714396809071\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(tf_x_train,Y_train)\n",
    "y_test_pred=clf.predict(tf_x_test)\n",
    "y_train_pred=clf.predict(tf_x_train)\n",
    "from sklearn.metrics import classification_report\n",
    "report_train=classification_report(Y_train, y_train_pred,output_dict=True)\n",
    "#print(\"Logistic Regression Model:\")\n",
    "#print(\"Report for Traning data Classification\")\n",
    "#print(\"Accuracy:\",report_train['accuracy'])\n",
    "#print(\"Precision:\",precision_score(Y_train, y_train_pred))\n",
    "#print(\"Recall:\",recall_score(Y_train, y_train_pred))\n",
    "#print(\"f1_score:\",f1_score(Y_train, y_train_pred))\n",
    "#print(report_train)\n",
    "print(report_train['accuracy'],\",\",precision_score(Y_train, y_train_pred),\",\",recall_score(Y_train, y_train_pred),\",\",f1_score(Y_train, y_train_pred))\n",
    "report=classification_report(Y_test, y_test_pred,output_dict=True)\n",
    "#print(\"Report for Testing data Classification\")\n",
    "#print(\"Accuracy:\",report['accuracy'])\n",
    "#print(\"Precision:\",precision_score(Y_test, y_test_pred))\n",
    "#print(\"Recall:\",recall_score(Y_test, y_test_pred))\n",
    "#print(\"f1_score:\",f1_score(Y_test, y_test_pred))\n",
    "#print(report)\n",
    "print(report['accuracy'],\",\",precision_score(Y_test, y_test_pred),\",\",recall_score(Y_test, y_test_pred),\",\",f1_score(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.888925 , 0.8979179197112985 , 0.8775027826065207 , 0.8875929767747812\n",
      "0.868575 , 0.881884881678206 , 0.851739108737961 , 0.866549894651334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(tf_x_train,Y_train)\n",
    "y_test_pred=classifier.predict(tf_x_test)\n",
    "y_train_pred=classifier.predict(tf_x_train)\n",
    "report_train=classification_report(Y_train, y_train_pred,output_dict=True)\n",
    "#print(\"Naive Bayes Model:\")\n",
    "#print(\"Report for Traning data Classification\")\n",
    "#print(\"Accuracy:\",report_train['accuracy'])\n",
    "#print(\"Precision:\",precision_score(Y_train, y_train_pred))\n",
    "#print(\"Recall:\",recall_score(Y_train, y_train_pred))\n",
    "#print(\"f1_score:\",f1_score(Y_train, y_train_pred))\n",
    "#print(report_train)\n",
    "print(report_train['accuracy'],\",\",precision_score(Y_train, y_train_pred),\",\",recall_score(Y_train, y_train_pred),\",\",f1_score(Y_train, y_train_pred))\n",
    "report=classification_report(Y_test, y_test_pred,output_dict=True)\n",
    "#print(\"Report for Testing data Classification\")\n",
    "#print(\"Accuracy:\",report['accuracy'])\n",
    "#print(\"Precision:\",precision_score(Y_test, y_test_pred))\n",
    "#print(\"Recall:\",recall_score(Y_test, y_test_pred))\n",
    "#print(\"f1_score:\",f1_score(Y_test, y_test_pred))\n",
    "#print(report)\n",
    "print(report['accuracy'],\",\",precision_score(Y_test, y_test_pred),\",\",recall_score(Y_test, y_test_pred),\",\",f1_score(Y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nltk version is 3.5.\n",
      "The scikit-learn version is 0.23.2.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import sklearn\n",
    "print('The nltk version is {}.'.format(nltk.__version__))\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
